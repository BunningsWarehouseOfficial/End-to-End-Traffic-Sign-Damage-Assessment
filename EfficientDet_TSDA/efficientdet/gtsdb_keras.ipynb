{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import PIL\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "#os.system(pip3 install -r requirements.txt\n",
    "#os.system(cat requirements.system | xargs sudo apt install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = 'd0'  # @param\n",
    "MODEL = 'efficientdet-' + model_size\n",
    "\n",
    "experiment_modifiers = 'optimizer=adam-anchor_scale=1.5--simple'  # @param\n",
    "model_dir = '/home/allenator/Pawsey-Internship/model_dir'\n",
    "temp_model_dir = '/home/allenator/Pawsey-Internship/model_dir/temp'\n",
    "gtsdb_dir = \"/home/allenator/Pawsey-Internship/datasets/gtsdb\"\n",
    "tfrecord_dir = \"/home/allenator/Pawsey-Internship/datasets/tfrecord_gtsdb\"\n",
    "latest_model_path = f'{model_dir}/{MODEL}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-11-30 15:36:16--  https://storage.googleapis.com/cloud-tpu-checkpoints/efficientdet/coco/efficientdet-d0.tar.gz\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.167.80, 172.217.24.48, 142.250.204.16, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.167.80|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 28994253 (28M) [application/octet-stream]\n",
      "Saving to: 'efficientdet-d0.tar.gz’\n",
      "\n",
      "efficientdet-d0.tar 100%[===================>]  27.65M  9.83MB/s    in 2.8s    \n",
      "\n",
      "2021-11-30 15:36:22 (9.83 MB/s) - 'efficientdet-d0.tar.gz’ saved [28994253/28994253]\n",
      "\n",
      "/home/allenator/Pawsey-Internship/model_dir/efficientdet-d0_cocoCkpt\n",
      "Use model in /home/allenator/Pawsey-Internship/model_dir/efficientdet-d0_cocoCkpt\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir('/home/allenator/Pawsey-Internship/model_dir'):\n",
    "    !mkdir /home/allenator/Pawsey-Internship/model_dir\n",
    "\n",
    "def download(m):\n",
    "    '''Downloads Google's checkpoint for the specified EfficientDet model.'''\n",
    "    ckpt_path = model_dir + f'/{m}_cocoCkpt'\n",
    "    if not os.path.isdir(ckpt_path):\n",
    "        !wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientdet/coco/{m}.tar.gz\n",
    "        !tar zxf {m}.tar.gz --directory {model_dir}\n",
    "        !mv {model_dir}/{m} {ckpt_path} \n",
    "        !rm {m}.tar.gz\n",
    "    print(ckpt_path)\n",
    "    return ckpt_path\n",
    "\n",
    "# Download checkpoint.\n",
    "coco_ckpt_path = download(MODEL)\n",
    "print('Use model in {}'.format(coco_ckpt_path))\n",
    "\n",
    "min_score_thresh = 0.0  # @param\n",
    "max_boxes_to_draw = 200  # @param\n",
    "line_thickness = 2  # @param\n",
    "batch_size = 4  # @param\n",
    "epochs = 350  # @param\n",
    "num_shards = 32 # @param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-11-30 15:42:49--  https://app.roboflow.com/ds/UQRkeMI1UW?key=TuRmW7Gi5I\n",
      "Resolving app.roboflow.com (app.roboflow.com)... 151.101.65.195, 151.101.1.195\n",
      "Connecting to app.roboflow.com (app.roboflow.com)|151.101.65.195|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://storage.googleapis.com/roboflow-platform-exports/TeS932oc95Z4Gd4Be83n29C0fIh1/zqlDUw6gB4mpfEcrcRWh/1/coco.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=roboflow-platform%40appspot.gserviceaccount.com%2F20211130%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20211130T074249Z&X-Goog-Expires=901&X-Goog-SignedHeaders=host&X-Goog-Signature=afd5b284f8229b0f9d7679f049946cfea139a11084a09e954c4851cf16603c55688498ea6f91cc7f0087403c7b6c1b987e2609b414573fdad5a45325374140c6a372dc6146e11e3ca7967715d1d18d6e5e6d7f2f4eac59a42076ab6da227fe03da7ff4390ecfacd8f318e4aa49e99e9665459798e63d3c3fcb32e1f10e70465e920991712181651aceee44b2a8c10d2aa107516e6d339ccbe31140338041b483bb7dfd73d12496e57dfe92db662a338514116852d4b1aeb914312ebf953305c95ffd623b36152198a965c6a6b1198b8f256736e70450d87f82b762f40fe7403355433b74be693b3b2f8ed096a86b5c51b1f826b080c2634ff4a5603b0dad0736 [following]\n",
      "--2021-11-30 15:42:50--  https://storage.googleapis.com/roboflow-platform-exports/TeS932oc95Z4Gd4Be83n29C0fIh1/zqlDUw6gB4mpfEcrcRWh/1/coco.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=roboflow-platform%40appspot.gserviceaccount.com%2F20211130%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20211130T074249Z&X-Goog-Expires=901&X-Goog-SignedHeaders=host&X-Goog-Signature=afd5b284f8229b0f9d7679f049946cfea139a11084a09e954c4851cf16603c55688498ea6f91cc7f0087403c7b6c1b987e2609b414573fdad5a45325374140c6a372dc6146e11e3ca7967715d1d18d6e5e6d7f2f4eac59a42076ab6da227fe03da7ff4390ecfacd8f318e4aa49e99e9665459798e63d3c3fcb32e1f10e70465e920991712181651aceee44b2a8c10d2aa107516e6d339ccbe31140338041b483bb7dfd73d12496e57dfe92db662a338514116852d4b1aeb914312ebf953305c95ffd623b36152198a965c6a6b1198b8f256736e70450d87f82b762f40fe7403355433b74be693b3b2f8ed096a86b5c51b1f826b080c2634ff4a5603b0dad0736\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.67.16, 142.250.71.80, 142.250.76.112, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.67.16|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 122887848 (117M) [application/zip]\n",
      "Saving to: 'gtsdb.zip’\n",
      "\n",
      "gtsdb.zip           100%[===================>] 117.19M  11.1MB/s    in 11s     \n",
      "\n",
      "2021-11-30 15:43:02 (10.9 MB/s) - 'gtsdb.zip’ saved [122887848/122887848]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get GTSDB datasety (in COCO format) from Roboflow\n",
    "if not os.path.isdir(gtsdb_dir):\n",
    "    !mkdir {gtsdb_dir}\n",
    "    !wget \"https://app.roboflow.com/ds/UQRkeMI1UW?key=TuRmW7Gi5I\" -O gtsdb.zip\n",
    "    !unzip -q gtsdb.zip -d {gtsdb_dir}\n",
    "    !rm gtsdb.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = '_annotations.coco.json'  # Default\n",
    "single_annotations = '_single_annotations.coco.json'\n",
    "\n",
    "import json\n",
    "\n",
    "# Convert original GTSDB label mappings to labels with a single sign class\n",
    "def convert_to_single_label(dataset, new_label_map, original_annotations, new_annotations):\n",
    "    with open(os.path.join(dataset, original_annotations), 'r') as a_file:\n",
    "        # Read and modify the original annotations in memory\n",
    "        a_json = json.load(a_file)\n",
    "\n",
    "        ii = 0\n",
    "        categories = []\n",
    "        for category in new_label_map:\n",
    "            cat_super = \"none\" if ii == 0 else \"signs\"\n",
    "            categories.append({\n",
    "                \"id\": ii,\n",
    "                \"name\": new_label_map[ii],\n",
    "                \"supercategory\": cat_super\n",
    "            })\n",
    "            ii += 1\n",
    "        a_json['categories'] = categories\n",
    "        \n",
    "        annotations = []\n",
    "        for annotation in a_json['annotations']:\n",
    "            annotation['category_id'] = 1\n",
    "            annotations.append(annotation)\n",
    "        a_json['annotations'] = annotations\n",
    "\n",
    "        # Write the updated annotations to a new file\n",
    "        with open(os.path.join(dataset, new_annotations), 'w') as a_file_new:\n",
    "            json.dump(a_json, a_file_new, indent=4)\n",
    "\n",
    "\n",
    "#FIXME: Label map currently has to be manually updated in hparamats_config.py, change so that it's auto-changed here\n",
    "# Use a single class label map\n",
    "single_label_map = {\n",
    "    0: 'signs',\n",
    "    1: 'traffic_sign'\n",
    "}\n",
    "label_map = single_label_map\n",
    "convert_to_single_label(f\"{gtsdb_dir}/train\", single_label_map, annotations, single_annotations)\n",
    "convert_to_single_label(f\"{gtsdb_dir}/valid\", single_label_map, annotations, single_annotations)\n",
    "convert_to_single_label(f\"{gtsdb_dir}/test\", single_label_map, annotations, single_annotations)\n",
    "annotations = single_annotations\n",
    "\n",
    "\n",
    "# Use a simplified, categorical label map\n",
    "#TODO: Extend to allow 'binning'/'merging' of larger into smaller non-1-class label map\n",
    "# simplified_label_map = {\n",
    "#     0: 'signs',\n",
    "#     1: 'warning',\n",
    "#     2: 'speed_limit',\n",
    "#     3: 'regulatory',\n",
    "#     4: 'restriction_ends',\n",
    "#     5: 'regulatory_direction',\n",
    "#     6: 'yield',\n",
    "#     7: 'stop',\n",
    "#     8: 'priority_road'\n",
    "# }\n",
    "# convert_label_map(\"gtsdb/train\", simplified_label_map)\n",
    "# convert_label_map(\"gtsdb/valid\", simplified_label_map)\n",
    "# convert_label_map(\"gtsdb/test\", simplified_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting training dataset to .tfrecord\n",
      "I1130 15:45:44.650909 140104939177792 create_coco_tfrecord.py:285] writing to output path: /home/allenator/Pawsey-Internship/tfrecord_gtsdb/train\n",
      "I1130 15:45:44.663876 140104939177792 create_coco_tfrecord.py:215] Building bounding box index.\n",
      "I1130 15:45:44.664365 140104939177792 create_coco_tfrecord.py:226] 120 images are missing bboxes.\n",
      "I1130 15:45:44.708741 140104939177792 create_coco_tfrecord.py:323] On image 0 of 629\n",
      "I1130 15:45:44.776468 140104939177792 create_coco_tfrecord.py:323] On image 100 of 629\n",
      "I1130 15:45:44.842713 140104939177792 create_coco_tfrecord.py:323] On image 200 of 629\n",
      "I1130 15:45:44.918726 140104939177792 create_coco_tfrecord.py:323] On image 300 of 629\n",
      "I1130 15:45:44.971158 140104939177792 create_coco_tfrecord.py:323] On image 400 of 629\n",
      "I1130 15:45:45.026265 140104939177792 create_coco_tfrecord.py:323] On image 500 of 629\n",
      "I1130 15:45:45.080399 140104939177792 create_coco_tfrecord.py:323] On image 600 of 629\n",
      "I1130 15:45:45.161181 140104939177792 create_coco_tfrecord.py:334] Finished writing, skipped 0 annotations.\n",
      "\n",
      "Converting validation dataset to .tfrecord\n",
      "I1130 15:45:46.898173 140130385897280 create_coco_tfrecord.py:285] writing to output path: /home/allenator/Pawsey-Internship/tfrecord_gtsdb/valid\n",
      "I1130 15:45:46.900492 140130385897280 create_coco_tfrecord.py:215] Building bounding box index.\n",
      "I1130 15:45:46.900599 140130385897280 create_coco_tfrecord.py:226] 27 images are missing bboxes.\n",
      "I1130 15:45:46.950916 140130385897280 create_coco_tfrecord.py:323] On image 0 of 180\n",
      "I1130 15:45:47.011848 140130385897280 create_coco_tfrecord.py:323] On image 100 of 180\n",
      "I1130 15:45:47.061471 140130385897280 create_coco_tfrecord.py:334] Finished writing, skipped 0 annotations.\n",
      "\n",
      "Converting test dataset to .tfrecord\n",
      "I1130 15:45:48.838262 140585628694336 create_coco_tfrecord.py:285] writing to output path: /home/allenator/Pawsey-Internship/tfrecord_gtsdb/test\n",
      "I1130 15:45:48.840078 140585628694336 create_coco_tfrecord.py:215] Building bounding box index.\n",
      "I1130 15:45:48.840175 140585628694336 create_coco_tfrecord.py:226] 12 images are missing bboxes.\n",
      "I1130 15:45:48.884648 140585628694336 create_coco_tfrecord.py:323] On image 0 of 90\n",
      "I1130 15:45:48.949657 140585628694336 create_coco_tfrecord.py:334] Finished writing, skipped 0 annotations.\n"
     ]
    }
   ],
   "source": [
    "# Convert datasets into .tfrecord files that can be read by model\n",
    "import dataset\n",
    "if not os.path.isdir(tfrecord_dir):\n",
    "    !mkdir {tfrecord_dir}\n",
    "\n",
    "#FIXME: num_shards and the annotation file variables don't work and need to be hardcoded\n",
    "train_file = f'{gtsdb_dir}/train/{annotations}'\n",
    "valid_file = f'{gtsdb_dir}/valid/{annotations}'\n",
    "test_file  = f'{gtsdb_dir}/test/{annotations}'\n",
    "\n",
    "# Train\n",
    "print(\"Converting training dataset to .tfrecord\")\n",
    "!PYTHONPATH=\".:$PYTHONPATH\"  python3 dataset/create_coco_tfrecord.py \\\n",
    "        --image_dir=/home/allenator/Pawsey-Internship/datasets/gtsdb/train \\\n",
    "        --object_annotations_file=/home/allenator/Pawsey-Internship/datasets/gtsdb/train/_single_annotations.coco.json \\\n",
    "        --output_file_prefix=/home/allenator/Pawsey-Internship/tfrecord_gtsdb/train \\\n",
    "        --num_shards=32\n",
    "\n",
    "# Validation\n",
    "print(\"\\nConverting validation dataset to .tfrecord\")\n",
    "!PYTHONPATH=\".:$PYTHONPATH\"  python3 dataset/create_coco_tfrecord.py \\\n",
    "        --image_dir=/home/allenator/Pawsey-Internship/datasets/gtsdb/valid \\\n",
    "        --object_annotations_file=/home/allenator/Pawsey-Internship/datasets/gtsdb/valid/_single_annotations.coco.json \\\n",
    "        --output_file_prefix=/home/allenator/Pawsey-Internship/tfrecord_gtsdb/valid \\\n",
    "        --num_shards=32\n",
    "\n",
    "# Test\n",
    "print(\"\\nConverting test dataset to .tfrecord\")\n",
    "!PYTHONPATH=\".:$PYTHONPATH\"  python3 dataset/create_coco_tfrecord.py \\\n",
    "        --image_dir=/home/allenator/Pawsey-Internship/datasets/gtsdb/test \\\n",
    "        --object_annotations_file=/home/allenator/Pawsey-Internship/datasets/gtsdb/test/_single_annotations.coco.json \\\n",
    "        --output_file_prefix=/home/allenator/Pawsey-Internship/tfrecord_gtsdb/test \\\n",
    "        --num_shards=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images_per_epoch = 608\n"
     ]
    }
   ],
   "source": [
    "# Count the number of .tfrecord shards to determine the no. of images per epoch\n",
    "num_train = len(tf.io.gfile.glob(f'{gtsdb_dir}/train/*.jpg'))\n",
    "images_per_epoch = (num_train // num_shards) * len(tf.io.gfile.glob(f'{tfrecord_dir}/train*'))\n",
    "images_per_epoch = int((images_per_epoch // 8) * 8)  # Round to a multiple of 64\n",
    "print('images_per_epoch = {}'.format(images_per_epoch))\n",
    "\n",
    "valid_file_pattern = 'valid*' \n",
    "train_file_pattern = 'train*'  \n",
    "num_valid = int(len(tf.io.gfile.glob(f'{gtsdb_dir}/valid/*.jpg')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using ImageNet checkpoint for backbone\n",
    "Transfer learning from pretrained *EfficientNetV1* ImageNet weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "# Train using the dataset converted to TFRecord above by create_coco_tfrecord.py\n",
    "# NOTE: If one of the parameter variables hasn't been defined, then *none* of the parameters will be recognised\n",
    "!LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4 \n",
    "\n",
    "total_epochs = 0\n",
    "\n",
    "if os.path.isdir(latest_model_path):\n",
    "        if glob(f'{latest_model_path}-*'):\n",
    "                prev_ckpt = glob(f'{latest_model_path}-*')[0]\n",
    "                prev_ckpt_name = os.path.basename(prev_ckpt)\n",
    "                total_epochs += int(prev_ckpt_name.split('-')[-1])\n",
    "                !rm -rf prev_ckpt\n",
    "        \n",
    "        latest_ckpt = tf.train.latest_checkpoint(latest_model_path)\n",
    "        latest_ckpt_name = os.path.splitext(os.path.basename(latest_ckpt))[0]\n",
    "        num_epoch = int(latest_ckpt_name.split('-')[-1])\n",
    "        total_epochs += num_epoch\n",
    "        new_path = latest_model_path + '-' + str(total_epochs)       \n",
    "                       \n",
    "        !mv {latest_model_path} {new_path}\n",
    "\n",
    "        os.system(f\"python3 keras_train.py --mode=traineval \\\n",
    "                --train_file_pattern={tfrecord_dir}/{train_file_pattern} \\\n",
    "                --val_file_pattern={tfrecord_dir}/{valid_file_pattern} \\\n",
    "                --model_name={MODEL} \\\n",
    "                --pretrained_ckpt={new_path} \\\n",
    "                --model_dir={latest_model_path} \\\n",
    "                --eval_samples={num_valid} \\\n",
    "                --num_examples_per_epoch={num_train} \\\n",
    "                --num_epochs={epochs} \\\n",
    "                --batch_size={batch_size} \\\n",
    "                --hparams='num_classes=41,moving_average_decay=0,optimizer=adam,anchor_scale=1.5'\")\n",
    "else:\n",
    "        os.system(f\"python3 keras_train.py --mode=traineval \\\n",
    "                --train_file_pattern={tfrecord_dir}/{train_file_pattern} \\\n",
    "                --val_file_pattern={tfrecord_dir}/{valid_file_pattern} \\\n",
    "                --model_name={MODEL} \\\n",
    "                --pretrained_ckpt={coco_ckpt_path} \\\n",
    "                --model_dir={latest_model_path} \\\n",
    "                --eval_samples={num_valid} \\\n",
    "                --num_examples_per_epoch={num_train} \\\n",
    "                --num_epochs={epochs} \\\n",
    "                --batch_size={batch_size} \\\n",
    "                --hparams='num_classes=41,moving_average_decay=0,optimizer=adam,anchor_scale=1.5'\")\n",
    "total_epochs += epochs\n",
    "print('Trained up to', total_epochs)\n",
    "\n",
    "\n",
    "#TODO: Print the weird epoch thing joined path in keras/train_lib.get_callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /home/Allenator/model_dir/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {latest_model_path}\n",
    "!PYTHONPATH=\".:$PYTHONPATH\" python3 model_inspect.py --runmode=saved_model --model_name={MODEL} \\\n",
    "  --ckpt_path={latest_model_path} \\\n",
    "  --saved_model_dir={temp_model_dir} \\\n",
    "  --hparams='num_classes=41,moving_average_decay=0,mixed_precision=True,optimizer=adam,anchor_scale=1.5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then run saved_model_infer to do inference.\n",
    "# Notably: batch_size, image_size must be the same as when it is exported.\n",
    "serve_image_out = 'serve_image_out'\n",
    "if not os.path.isdir(serve_image_out):\n",
    "  !mkdir {serve_image_out}\n",
    "\n",
    "# Image inference\n",
    "# saved_model_dir must be defined before running this cell!\n",
    "!python3 model_inspect.py --runmode=saved_model_infer \\\n",
    "  --saved_model_dir={saved_model_dir} \\\n",
    "  --model_name={MODEL} \\\n",
    "  --input_image='SGTS_Sequences_exp/*.jpg' \\\n",
    "  --output_image_dir={serve_image_out} \\\n",
    "  --min_score_thresh={min_score_thresh} \\\n",
    "  --max_boxes_to_draw={max_boxes_to_draw}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video inference\n",
    "!python3 model_inspect.py --runmode=saved_model_video \\\n",
    "  --saved_model_dir={saved_model_dir} \\\n",
    "  --model_name={MODEL} \\\n",
    "  --ckpt_path={ckpt_dir} \\\n",
    "  --hparams='num_classes=41,moving_average_decay=0,mixed_precision=True,optimizer=adam,anchor_scale=1.5' \\\n",
    "  --input_video=9.mov --output_video=output_9.mov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "# NOTE: These values are to take precedence over the eval values generated and graphed during training when comparing models\n",
    "!python3 keras_eval.py --model_name={MODEL} \\\n",
    "    --val_file_pattern=tfrecord_gtsdb/{valid_file_pattern} \\\n",
    "    --model_dir={ckpt_dir} \\\n",
    "    --eval_samples={num_valid} \\\n",
    "    --batch_size={batch_size} \\\n",
    "    --hparams='num_classes=41,moving_average_decay=0,mixed_precision=True,optimizer=adam,anchor_scale=1.5'"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4650a0716e19ebb99494a1d40cd29a8ffc3bbcd1e1b94096a8f2db492ccb7573"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
